{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b91f48",
   "metadata": {},
   "source": [
    "Online network and target network, use one view to predict the other, does not rely on negative pairs.\n",
    "\n",
    "Directly bootstrap the representation\n",
    "\n",
    "Predicting directly in representation space can lead to collapsed representations. To avoid the collapse, we use a fixed randomly initialized network to produce the target, and update it with a slow moving average of the online network (simsiam told us this is not necessary) \n",
    "\n",
    "$x$ --$t$--> view $v$ --$f_\\theta$-->representation $y_\\theta$ --$g_\\theta$ --> projection $z_\\theta$-- q_\\theta --> prediction $q_\\theta(z_\\theta)$\n",
    "\n",
    "target: $x$ --$t'$--> view $v'$ --$f_\\xi$-->representation $y'_\\xi$ --$g_\\xi$ --> projection $z'_\\xi$--sg--> prediction $sg(z'_\\xi)$\n",
    "\n",
    "$q_\\theta(z_\\theta)--online-->sg(z'_\\xi)$ \n",
    "\n",
    "$$L_{\\theta, \\xi} = \\left\\|\\frac{q_\\theta(z_\\theta)}{\\|q_{\\theta(z_\\theta)}\\|}-\\frac{z'_\\xi}{\\|z'_\\xi\\|}\\right\\|$$\n",
    "\n",
    "Symmetrize the loss by exchanging $v'$ and $v$ to compute $\\tilde{L}_{\\theta, \\xi}$.\n",
    "\n",
    "Optimization: $L_{\\theta,\\xi}^{\\text{BYOL}}=L_{\\theta,\\xi}+\\tilde{L}_{\\theta, \\xi}$.\n",
    "\n",
    "$$\\theta \\leftarrow \\text{optimizer}(\\theta, \\nabla L_{\\theta, \\xi}^{\\text{BYOL}},\\eta).$$\n",
    "$$\\xi\\leftarrow \\tau \\xi +(1-\\tau)\\theta.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466806db",
   "metadata": {
    "code_folding": [
     7,
     12
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def byol_loss_func(p: torch.Tensor, z: torch.Tensor, simplified: bool = True) -> torch.Tensor:\n",
    "    \"\"\"Computes BYOL's loss given batch of predicted features p and projected momentum features z.\n",
    "\n",
    "    Args:\n",
    "        p (torch.Tensor): NxD Tensor containing predicted features from view 1\n",
    "        z (torch.Tensor): NxD Tensor containing projected momentum features from view 2\n",
    "        simplified (bool): faster computation, but with same result. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: BYOL's loss.\n",
    "    \"\"\"\n",
    "\n",
    "    if simplified:\n",
    "        return 2 - 2 * F.cosine_similarity(p, z.detach(), dim=-1).mean()\n",
    "    else:\n",
    "        p = F.normalize(p, dim=-1)\n",
    "        z = F.normalize(z, dim=-1)\n",
    "\n",
    "        return 2 - 2 * (p * z.detach()).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924a893",
   "metadata": {
    "code_folding": [
     30,
     69
    ]
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Any, Dict, List, Sequence, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from solo.losses.byol import byol_loss_func\n",
    "from solo.methods.base import BaseMomentumModel\n",
    "from solo.utils.momentum import initialize_momentum_params\n",
    "\n",
    "\n",
    "class BYOL(BaseMomentumModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim: int,\n",
    "        proj_hidden_dim: int,\n",
    "        pred_hidden_dim: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Implements BYOL (https://arxiv.org/abs/2006.07733).\n",
    "\n",
    "        Args:\n",
    "            output_dim (int): number of dimensions of projected features.\n",
    "            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n",
    "            pred_hidden_dim (int): number of neurons of the hidden layers of the predictor.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # projector\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.features_dim, proj_hidden_dim),\n",
    "            nn.BatchNorm1d(proj_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "        # momentum projector\n",
    "        self.momentum_projector = nn.Sequential(\n",
    "            nn.Linear(self.features_dim, proj_hidden_dim),\n",
    "            nn.BatchNorm1d(proj_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_hidden_dim, output_dim),\n",
    "        )\n",
    "        initialize_momentum_params(self.projector, self.momentum_projector)\n",
    "\n",
    "        # predictor\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(output_dim, pred_hidden_dim),\n",
    "            nn.BatchNorm1d(pred_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(pred_hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n",
    "        parent_parser = super(BYOL, BYOL).add_model_specific_args(parent_parser)\n",
    "        parser = parent_parser.add_argument_group(\"byol\")\n",
    "\n",
    "        # projector\n",
    "        parser.add_argument(\"--output_dim\", type=int, default=256)\n",
    "        parser.add_argument(\"--proj_hidden_dim\", type=int, default=2048)\n",
    "\n",
    "        # predictor\n",
    "        parser.add_argument(\"--pred_hidden_dim\", type=int, default=512)\n",
    "\n",
    "        return parent_parser\n",
    "\n",
    "    @property\n",
    "    def learnable_params(self) -> List[dict]:\n",
    "        \"\"\"Adds projector and predictor parameters to the parent's learnable parameters.\n",
    "\n",
    "        Returns:\n",
    "            List[dict]: list of learnable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        extra_learnable_params = [\n",
    "            {\"params\": self.projector.parameters()},\n",
    "            {\"params\": self.predictor.parameters()},\n",
    "        ]\n",
    "        return super().learnable_params + extra_learnable_params\n",
    "\n",
    "    @property\n",
    "    def momentum_pairs(self) -> List[Tuple[Any, Any]]:\n",
    "        \"\"\"Adds (projector, momentum_projector) to the parent's momentum pairs.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[Any, Any]]: list of momentum pairs.\n",
    "        \"\"\"\n",
    "\n",
    "        extra_momentum_pairs = [(self.projector, self.momentum_projector)]\n",
    "        return super().momentum_pairs + extra_momentum_pairs\n",
    "\n",
    "    def forward(self, X: torch.Tensor, *args, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Performs forward pass of the online encoder (encoder, projector and predictor).\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): batch of images in tensor format.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: a dict containing the outputs of the parent and the logits of the head.\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().forward(X, *args, **kwargs)\n",
    "        z = self.projector(out[\"feats\"])\n",
    "        p = self.predictor(z)\n",
    "        return {**out, \"z\": z, \"p\": p}\n",
    "\n",
    "    def training_step(self, batch: Sequence[Any], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step for BYOL reusing BaseModel training step.\n",
    "\n",
    "        Args:\n",
    "            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n",
    "                [X] is a list of size self.num_crops containing batches of images.\n",
    "            batch_idx (int): index of the batch.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: total loss composed of BYOL and classification loss.\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().training_step(batch, batch_idx)\n",
    "        class_loss = out[\"loss\"]\n",
    "        feats1, feats2 = out[\"feats\"]\n",
    "        momentum_feats1, momentum_feats2 = out[\"momentum_feats\"]\n",
    "\n",
    "        z1 = self.projector(feats1)\n",
    "        z2 = self.projector(feats2)\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "\n",
    "        # forward momentum encoder\n",
    "        with torch.no_grad():\n",
    "            z1_momentum = self.momentum_projector(momentum_feats1)\n",
    "            z2_momentum = self.momentum_projector(momentum_feats2)\n",
    "\n",
    "        # ------- contrastive loss -------\n",
    "        neg_cos_sim = byol_loss_func(p1, z2_momentum) + byol_loss_func(p2, z1_momentum)\n",
    "\n",
    "        # calculate std of features\n",
    "        z1_std = F.normalize(z1, dim=-1).std(dim=0).mean()\n",
    "        z2_std = F.normalize(z2, dim=-1).std(dim=0).mean()\n",
    "        z_std = (z1_std + z2_std) / 2\n",
    "\n",
    "        metrics = {\n",
    "            \"train_neg_cos_sim\": neg_cos_sim,\n",
    "            \"train_z_std\": z_std,\n",
    "        }\n",
    "        self.log_dict(metrics, on_epoch=True, sync_dist=True)\n",
    "\n",
    "        return neg_cos_sim + class_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
