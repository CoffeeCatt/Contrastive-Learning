{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e35b9d7c",
   "metadata": {},
   "source": [
    "Siamese networks: stop gradient operation plays an essential role in preventing collapsing.\n",
    "\n",
    "BYOL without the momentum encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def simsiam_loss_func(p: torch.Tensor, z: torch.Tensor, simplified: bool = True) -> torch.Tensor:\n",
    "    \"\"\"Computes SimSiam's loss given batch of predicted features p from view 1 and\n",
    "    a batch of projected features z from view 2.\n",
    "\n",
    "    Args:\n",
    "        p (torch.Tensor): Tensor containing predicted features from view 1.\n",
    "        z (torch.Tensor): Tensor containing projected features from view 2.\n",
    "        simplified (bool): faster computation, but with same result.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: SimSiam loss.\n",
    "    \"\"\"\n",
    "\n",
    "    if simplified:\n",
    "        return -F.cosine_similarity(p, z.detach(), dim=-1).mean()\n",
    "    else:\n",
    "        p = F.normalize(p, dim=-1)\n",
    "        z = F.normalize(z, dim=-1)\n",
    "\n",
    "        return -(p * z.detach()).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a156ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Any, Dict, List, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from solo.losses.simsiam import simsiam_loss_func\n",
    "from solo.methods.base import BaseModel\n",
    "\n",
    "\n",
    "class SimSiam(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim: int,\n",
    "        proj_hidden_dim: int,\n",
    "        pred_hidden_dim: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Implements SimSiam (https://arxiv.org/abs/2011.10566).\n",
    "\n",
    "        Args:\n",
    "            output_dim (int): number of dimensions of projected features.\n",
    "            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n",
    "            pred_hidden_dim (int): number of neurons of the hidden layers of the predictor.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # projector\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.features_dim, proj_hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(proj_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_hidden_dim, proj_hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(proj_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_hidden_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim, affine=False),\n",
    "        )\n",
    "        self.projector[6].bias.requires_grad = False  # hack: not use bias as it is followed by BN\n",
    "\n",
    "        # predictor\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(output_dim, pred_hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(pred_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(pred_hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n",
    "        parent_parser = super(SimSiam, SimSiam).add_model_specific_args(parent_parser)\n",
    "        parser = parent_parser.add_argument_group(\"simsiam\")\n",
    "\n",
    "        # projector\n",
    "        parser.add_argument(\"--output_dim\", type=int, default=128)\n",
    "        parser.add_argument(\"--proj_hidden_dim\", type=int, default=2048)\n",
    "\n",
    "        # predictor\n",
    "        parser.add_argument(\"--pred_hidden_dim\", type=int, default=512)\n",
    "        return parent_parser\n",
    "\n",
    "    @property\n",
    "    def learnable_params(self) -> List[dict]:\n",
    "        \"\"\"Adds projector and predictor parameters to the parent's learnable parameters.\n",
    "\n",
    "        Returns:\n",
    "            List[dict]: list of learnable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        extra_learnable_params: List[dict] = [\n",
    "            {\"params\": self.projector.parameters()},\n",
    "            {\"params\": self.predictor.parameters(), \"static_lr\": True},\n",
    "        ]\n",
    "        return super().learnable_params + extra_learnable_params\n",
    "\n",
    "    def forward(self, X: torch.Tensor, *args, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Performs the forward pass of the encoder, the projector and the predictor.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): a batch of images in the tensor format.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]:\n",
    "                a dict containing the outputs of the parent\n",
    "                and the projected and predicted features.\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().forward(X, *args, **kwargs)\n",
    "        z = self.projector(out[\"feats\"])\n",
    "        p = self.predictor(z)\n",
    "        return {**out, \"z\": z, \"p\": p}\n",
    "\n",
    "    def training_step(self, batch: Sequence[Any], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step for SimSiam reusing BaseModel training step.\n",
    "\n",
    "        Args:\n",
    "            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n",
    "                [X] is a list of size self.num_crops containing batches of images\n",
    "            batch_idx (int): index of the batch\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: total loss composed of SimSiam loss and classification loss\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().training_step(batch, batch_idx)\n",
    "        class_loss = out[\"loss\"]\n",
    "        feats1, feats2 = out[\"feats\"]\n",
    "\n",
    "        z1 = self.projector(feats1)\n",
    "        z2 = self.projector(feats2)\n",
    "\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "\n",
    "        # ------- contrastive loss -------\n",
    "        neg_cos_sim = simsiam_loss_func(p1, z2) / 2 + simsiam_loss_func(p2, z1) / 2\n",
    "\n",
    "        # calculate std of features\n",
    "        z1_std = F.normalize(z1, dim=-1).std(dim=0).mean()\n",
    "        z2_std = F.normalize(z2, dim=-1).std(dim=0).mean()\n",
    "        z_std = (z1_std + z2_std) / 2\n",
    "\n",
    "        metrics = {\n",
    "            \"train_neg_cos_sim\": neg_cos_sim,\n",
    "            \"train_z_std\": z_std,\n",
    "        }\n",
    "        self.log_dict(metrics, on_epoch=True, sync_dist=True)\n",
    "\n",
    "        return neg_cos_sim + class_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
