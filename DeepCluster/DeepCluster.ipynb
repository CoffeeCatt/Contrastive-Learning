{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternating between clustering of the image descriptors and updating the weights of the convnet by predicting the cluster assignment.\n",
    "\n",
    "K-means(need to read implement again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def deepclusterv2_loss_func(\n",
    "    outputs: torch.Tensor, assignments: torch.Tensor, temperature: float = 0.1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Computes DeepClusterV2's loss given a tensor containing logits from multiple views\n",
    "    and a tensor containing cluster assignments from the same multiple views.\n",
    "    Args:\n",
    "        outputs (torch.Tensor): tensor of size PxVxNxC where P is the number of prototype\n",
    "            layers and V is the number of views.\n",
    "        assignments (torch.Tensor): tensor of size PxVxNxC containing the assignments\n",
    "            generated using k-means.\n",
    "        temperature (float, optional): softmax temperature for the loss. Defaults to 0.1.\n",
    "    Returns:\n",
    "        torch.Tensor: DeepClusterV2 loss.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for h in range(outputs.size(0)):\n",
    "        scores = outputs[h].view(-1, outputs.size(-1)) / temperature\n",
    "        targets = assignments[h].repeat(outputs.size(1)).to(outputs.device, non_blocking=True)\n",
    "        loss += F.cross_entropy(scores, targets, ignore_index=-1)\n",
    "    return loss / outputs.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10,
     19
    ]
   },
   "outputs": [],
   "source": [
    "from typing import Any, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(\n",
    "        self,\n",
    "        world_size: int,\n",
    "        rank: int,\n",
    "        num_crops: int,\n",
    "        dataset_size: int,\n",
    "        proj_features_dim: int,\n",
    "        num_prototypes: int,\n",
    "        kmeans_iters: int = 10,\n",
    "    ):\n",
    "        \"\"\"Class that performs K-Means on the hypersphere.\n",
    "\n",
    "        Args:\n",
    "            world_size (int): world size.\n",
    "            rank (int): rank of the current process.\n",
    "            num_crops (int): number of crops.\n",
    "            dataset_size (int): total size of the dataset (number of samples).\n",
    "            proj_features_dim (int): number of dimensions of the projected features.\n",
    "            num_prototypes (int): number of prototypes.\n",
    "            kmeans_iters (int, optional): number of iterations for the k-means clustering.\n",
    "                Defaults to 10.\n",
    "        \"\"\"\n",
    "        self.world_size = world_size\n",
    "        self.rank = rank\n",
    "        self.num_crops = num_crops\n",
    "        self.dataset_size = dataset_size\n",
    "        self.proj_features_dim = proj_features_dim\n",
    "        self.num_prototypes = num_prototypes\n",
    "        self.kmeans_iters = kmeans_iters\n",
    "\n",
    "    @staticmethod\n",
    "    def get_indices_sparse(data: np.ndarray):\n",
    "        cols = np.arange(data.size)\n",
    "        M = csr_matrix((cols, (data.ravel(), cols)), shape=(int(data.max()) + 1, data.size))\n",
    "        return [np.unravel_index(row.data, data.shape) for row in M]\n",
    "\n",
    "    def cluster_memory(\n",
    "        self,\n",
    "        local_memory_index: torch.Tensor,\n",
    "        local_memory_embeddings: torch.Tensor,\n",
    "    ) -> Sequence[Any]:\n",
    "        \"\"\"Performs K-Means clustering on the hypersphere and returns centroids and\n",
    "        assignments for each sample.\n",
    "\n",
    "        Args:\n",
    "            local_memory_index (torch.Tensor): memory bank cointaining indices of the\n",
    "                samples.\n",
    "            local_memory_embeddings (torch.Tensor): memory bank cointaining embeddings\n",
    "                of the samples.\n",
    "\n",
    "        Returns:\n",
    "            Sequence[Any]: assignments and centroids.\n",
    "        \"\"\"\n",
    "        j = 0\n",
    "        device = local_memory_embeddings.device\n",
    "        assignments = -torch.ones(len(self.num_prototypes), self.dataset_size).long()\n",
    "        centroids_list = []\n",
    "        with torch.no_grad():\n",
    "            for i_K, K in enumerate(self.num_prototypes):\n",
    "                # run distributed k-means\n",
    "\n",
    "                # init centroids with elements from memory bank of rank 0\n",
    "                centroids = torch.empty(K, self.proj_features_dim).to(device, non_blocking=True)\n",
    "                if self.rank == 0:\n",
    "                    random_idx = torch.randperm(len(local_memory_embeddings[j]))[:K]\n",
    "                    assert len(random_idx) >= K, \"please reduce the number of centroids\"\n",
    "                    centroids = local_memory_embeddings[j][random_idx]\n",
    "                if dist.is_available() and dist.is_initialized():\n",
    "                    dist.broadcast(centroids, 0)\n",
    "\n",
    "                for n_iter in range(self.kmeans_iters + 1):\n",
    "\n",
    "                    # E step\n",
    "                    dot_products = torch.mm(local_memory_embeddings[j], centroids.t())\n",
    "                    _, local_assignments = dot_products.max(dim=1)\n",
    "\n",
    "                    # finish\n",
    "                    if n_iter == self.kmeans_iters:\n",
    "                        break\n",
    "\n",
    "                    # M step\n",
    "                    where_helper = self.get_indices_sparse(local_assignments.cpu().numpy())\n",
    "                    counts = torch.zeros(K).to(device, non_blocking=True).int()\n",
    "                    emb_sums = torch.zeros(K, self.proj_features_dim).to(device, non_blocking=True)\n",
    "                    for k in range(len(where_helper)):\n",
    "                        if len(where_helper[k][0]) > 0:\n",
    "                            emb_sums[k] = torch.sum(\n",
    "                                local_memory_embeddings[j][where_helper[k][0]],\n",
    "                                dim=0,\n",
    "                            )\n",
    "                            counts[k] = len(where_helper[k][0])\n",
    "                    if dist.is_available() and dist.is_initialized():\n",
    "                        dist.all_reduce(counts)\n",
    "                        dist.all_reduce(emb_sums)\n",
    "                    mask = counts > 0\n",
    "                    centroids[mask] = emb_sums[mask] / counts[mask].unsqueeze(1)\n",
    "\n",
    "                    # normalize centroids\n",
    "                    centroids = F.normalize(centroids, dim=1, p=2)\n",
    "\n",
    "                centroids_list.append(centroids)\n",
    "\n",
    "                if dist.is_available() and dist.is_initialized():\n",
    "                    # gather the assignments\n",
    "                    assignments_all = torch.empty(\n",
    "                        self.world_size,\n",
    "                        local_assignments.size(0),\n",
    "                        dtype=local_assignments.dtype,\n",
    "                        device=local_assignments.device,\n",
    "                    )\n",
    "                    assignments_all = list(assignments_all.unbind(0))\n",
    "\n",
    "                    dist_process = dist.all_gather(\n",
    "                        assignments_all, local_assignments, async_op=True\n",
    "                    )\n",
    "                    dist_process.wait()\n",
    "                    assignments_all = torch.cat(assignments_all).cpu()\n",
    "\n",
    "                    # gather the indexes\n",
    "                    indexes_all = torch.empty(\n",
    "                        self.world_size,\n",
    "                        local_memory_index.size(0),\n",
    "                        dtype=local_memory_index.dtype,\n",
    "                        device=local_memory_index.device,\n",
    "                    )\n",
    "                    indexes_all = list(indexes_all.unbind(0))\n",
    "                    dist_process = dist.all_gather(indexes_all, local_memory_index, async_op=True)\n",
    "                    dist_process.wait()\n",
    "                    indexes_all = torch.cat(indexes_all).cpu()\n",
    "\n",
    "                else:\n",
    "                    assignments_all = local_assignments\n",
    "                    indexes_all = local_memory_index\n",
    "\n",
    "                # log assignments\n",
    "                assignments[i_K][indexes_all] = assignments_all\n",
    "\n",
    "                # next memory bank to use\n",
    "                j = (j + 1) % self.num_crops\n",
    "\n",
    "        return assignments, centroids_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     12,
     20,
     56,
     72,
     81,
     127,
     140,
     155
    ]
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Any, Dict, List, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from solo.losses.deepclusterv2 import deepclusterv2_loss_func\n",
    "from solo.methods.base import BaseModel\n",
    "from solo.utils.kmeans import KMeans\n",
    "\n",
    "\n",
    "class DeepClusterV2(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim: int,\n",
    "        proj_hidden_dim: int,\n",
    "        num_prototypes: Sequence[int],\n",
    "        temperature: float,\n",
    "        kmeans_iters: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Implements DeepCluster V2 (https://arxiv.org/abs/2006.09882).\n",
    "        Args:\n",
    "            output_dim (int): number of dimensions of the projected features.\n",
    "            proj_hidden_dim (int): number of neurons in the hidden layers of the projector.\n",
    "            num_prototypes (Sequence[int]): number of prototypes.\n",
    "            temperature (float): temperature for the softmax.\n",
    "            kmeans_iters (int): number of iterations for k-means clustering.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.temperature = temperature\n",
    "        self.num_prototypes = num_prototypes\n",
    "        self.kmeans_iters = kmeans_iters\n",
    "\n",
    "        # projector\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.features_dim, proj_hidden_dim),\n",
    "            nn.BatchNorm1d(proj_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "        # prototypes\n",
    "        self.prototypes = nn.ModuleList(\n",
    "            [nn.Linear(output_dim, np, bias=False) for np in num_prototypes]\n",
    "        )\n",
    "        # normalize and set requires grad to false\n",
    "        for proto in self.prototypes:\n",
    "            for params in proto.parameters():\n",
    "                params.requires_grad = False\n",
    "            proto.weight.copy_(F.normalize(proto.weight.data.clone(), dim=-1))\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n",
    "        parent_parser = super(DeepClusterV2, DeepClusterV2).add_model_specific_args(parent_parser)\n",
    "        parser = parent_parser.add_argument_group(\"deepclusterv2\")\n",
    "\n",
    "        # projector\n",
    "        parser.add_argument(\"--output_dim\", type=int, default=128)\n",
    "        parser.add_argument(\"--proj_hidden_dim\", type=int, default=2048)\n",
    "\n",
    "        # parameters\n",
    "        parser.add_argument(\"--temperature\", type=float, default=0.1)\n",
    "        parser.add_argument(\"--num_prototypes\", type=int, nargs=\"+\", default=[3000, 3000, 3000])\n",
    "        parser.add_argument(\"--kmeans_iters\", type=int, default=10)\n",
    "\n",
    "        return parent_parser\n",
    "\n",
    "    @property\n",
    "    def learnable_params(self) -> List[dict]:\n",
    "        \"\"\"Adds projector and prototypes parameters to the parent's learnable parameters.\n",
    "        Returns:\n",
    "            List[dict]: list of learnable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        extra_learnable_params = [{\"params\": self.projector.parameters()}]\n",
    "        return super().learnable_params + extra_learnable_params\n",
    "\n",
    "    def on_train_start(self):\n",
    "        \"\"\"Gets the world size and initializes the memory banks.\"\"\"\n",
    "        #  k-means needs the world size and the dataset size\n",
    "        self.world_size = self.trainer.world_size if self.trainer else 1\n",
    "        self.dataset_size = getattr(self, \"dali_epoch_size\", None) or len(\n",
    "            self.trainer.train_dataloader.dataset\n",
    "        )\n",
    "\n",
    "        # build k-means helper object\n",
    "        self.kmeans = KMeans(\n",
    "            world_size=self.world_size,\n",
    "            rank=self.global_rank,\n",
    "            num_crops=self.num_crops,\n",
    "            dataset_size=self.dataset_size,\n",
    "            proj_features_dim=self.output_dim,\n",
    "            num_prototypes=self.num_prototypes,\n",
    "            kmeans_iters=self.kmeans_iters,\n",
    "        )\n",
    "\n",
    "        # initialize memory banks\n",
    "        size_memory_per_process = len(self.trainer.train_dataloader) * self.batch_size\n",
    "        self.register_buffer(\n",
    "            \"local_memory_index\",\n",
    "            torch.zeros(size_memory_per_process).long().to(self.device, non_blocking=True),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"local_memory_embeddings\",\n",
    "            F.normalize(\n",
    "                torch.randn(self.num_crops, size_memory_per_process, self.output_dim), dim=-1\n",
    "            ).to(self.device, non_blocking=True),\n",
    "        )\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        \"\"\"Prepares assigments and prototype centroids for the next epoch.\"\"\"\n",
    "\n",
    "        if self.current_epoch == 0:\n",
    "            self.assignments = -torch.ones(\n",
    "                len(self.num_prototypes), self.dataset_size, device=self.device\n",
    "            ).long()\n",
    "        else:\n",
    "            self.assignments, centroids = self.kmeans.cluster_memory(\n",
    "                self.local_memory_index, self.local_memory_embeddings\n",
    "            )\n",
    "            for proto, centro in zip(self.prototypes, centroids):\n",
    "                proto.weight.copy_(centro)\n",
    "\n",
    "    def update_memory_banks(self, idxs: torch.Tensor, z: torch.Tensor, batch_idx: int) -> None:\n",
    "        \"\"\"Updates DeepClusterV2's memory banks of indices and features.\n",
    "        Args:\n",
    "            idxs (torch.Tensor): set of indices of the samples of the current batch.\n",
    "            z (torch.Tensor): projected features of the samples of the current batch.\n",
    "            batch_idx (int): batch index relative to the current epoch.\n",
    "        \"\"\"\n",
    "\n",
    "        start_idx, end_idx = batch_idx * self.batch_size, (batch_idx + 1) * self.batch_size\n",
    "        self.local_memory_index[start_idx:end_idx] = idxs\n",
    "        for c, z_c in enumerate(z):\n",
    "            self.local_memory_embeddings[c][start_idx:end_idx] = z_c.detach()\n",
    "\n",
    "    def forward(self, X: torch.Tensor, *args, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Performs the forward pass of the encoder, the projector and the prototypes.\n",
    "        Args:\n",
    "            X (torch.Tensor): a batch of images in the tensor format.\n",
    "        Returns:\n",
    "            Dict[str, Any]:\n",
    "                a dict containing the outputs of the parent,\n",
    "                the projected features and the logits.\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().forward(X, *args, **kwargs)\n",
    "        z = F.normalize(self.projector(out[\"feats\"]))\n",
    "        p = torch.stack([p(z) for p in self.prototypes])\n",
    "        return {**out, \"z\": z, \"p\": p}\n",
    "\n",
    "    def training_step(self, batch: Sequence[Any], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step for DeepClusterV2 reusing BaseModel training step.\n",
    "        Args:\n",
    "            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n",
    "                [X] is a list of size self.num_crops containing batches of images.\n",
    "            batch_idx (int): index of the batch.\n",
    "        Returns:\n",
    "            torch.Tensor: total loss composed of DeepClusterV2 loss and classification loss.\n",
    "        \"\"\"\n",
    "\n",
    "        idxs = batch[0]\n",
    "\n",
    "        out = super().training_step(batch, batch_idx)\n",
    "        class_loss = out[\"loss\"]\n",
    "        feats1, feats2 = out[\"feats\"]\n",
    "\n",
    "        z1 = F.normalize(self.projector(feats1))\n",
    "        z2 = F.normalize(self.projector(feats2))\n",
    "\n",
    "        p1 = torch.stack([proto(z1) for proto in self.prototypes])\n",
    "        p2 = torch.stack([proto(z2) for proto in self.prototypes])\n",
    "\n",
    "        # ------- deepclusterv2 loss -------\n",
    "        preds = torch.stack([p1.unsqueeze(1), p2.unsqueeze(1)], dim=1)\n",
    "        assignments = self.assignments[:, idxs]\n",
    "        deepcluster_loss = deepclusterv2_loss_func(preds, assignments, self.temperature)\n",
    "\n",
    "        # ------- update memory banks -------\n",
    "        self.update_memory_banks(idxs, [z1, z2], batch_idx)\n",
    "\n",
    "        self.log(\"train_deepcluster_loss\", deepcluster_loss, on_epoch=True, sync_dist=True)\n",
    "\n",
    "        return deepcluster_loss + class_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
