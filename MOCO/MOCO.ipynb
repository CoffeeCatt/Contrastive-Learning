{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrastive learning as dictionary look-up.\n",
    "\n",
    "Build a dynamic dictionary with a queue and a moving averaged encoder. \n",
    "\n",
    "A desirable dictionary: large, consistent as they evolve during training (momentum update encoder).\n",
    "\n",
    "Hypothesize that such failure is caused by the rapidly changing encoder that reduces the\n",
    "key representationsâ€™ consistency.\n",
    "\n",
    "Personal comment: momentum update one projection head, simclr loss. \n",
    "negative samples from a queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     6
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def moco_loss_func(\n",
    "    query: torch.Tensor, key: torch.Tensor, queue: torch.Tensor, temperature=0.1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Computes MoCo's loss given a batch of queries from view 1, a batch of keys from view 2 and a\n",
    "    queue of past elements.\n",
    "\n",
    "    Args:\n",
    "        query (torch.Tensor): NxD Tensor containing the queries from view 1.\n",
    "        key (torch.Tensor): NxD Tensor containing the queries from view 2.\n",
    "        queue (torch.Tensor): a queue of negative samples for the contrastive loss.\n",
    "        temperature (float, optional): [description]. temperature of the softmax in the contrastive\n",
    "            loss. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: MoCo loss.\n",
    "    \"\"\"\n",
    "\n",
    "    pos = torch.einsum(\"nc,nc->n\", [query, key]).unsqueeze(-1)\n",
    "    neg = torch.einsum(\"nc,ck->nk\", [query, queue])\n",
    "    logits = torch.cat([pos, neg], dim=1)\n",
    "    logits /= temperature\n",
    "    targets = torch.zeros(query.size(0), device=query.device, dtype=torch.long)\n",
    "    return F.cross_entropy(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "class GatherLayer(torch.autograd.Function):\n",
    "    \"\"\"Gathers tensors from all processes, supporting backward propagation.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        if dist.is_available() and dist.is_initialized():\n",
    "            output = [torch.zeros_like(input) for _ in range(dist.get_world_size())]\n",
    "            dist.all_gather(output, input)\n",
    "        else:\n",
    "            output = [input]\n",
    "        return tuple(output)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *grads):\n",
    "        (input,) = ctx.saved_tensors\n",
    "        if dist.is_available() and dist.is_initialized():\n",
    "            grad_out = torch.zeros_like(input)\n",
    "            grad_out[:] = grads[dist.get_rank()]\n",
    "        else:\n",
    "            grad_out = grads[0]\n",
    "        return grad_out\n",
    "\n",
    "\n",
    "def gather(X, dim=0):\n",
    "    \"\"\"Gathers tensors from all processes, supporting backward propagation.\"\"\"\n",
    "    return torch.cat(GatherLayer.apply(X), dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     33,
     40,
     112,
     115,
     133,
     157
    ]
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Any, Dict, List, Sequence, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from solo.losses.moco import moco_loss_func\n",
    "from solo.methods.base import BaseMomentumModel\n",
    "from solo.utils.gather_layer import gather\n",
    "from solo.utils.momentum import initialize_momentum_params\n",
    "\n",
    "\n",
    "class MoCoV2Plus(BaseMomentumModel):\n",
    "    queue: torch.Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self, output_dim: int, proj_hidden_dim: int, temperature: float, queue_size: int, **kwargs\n",
    "    ):\n",
    "        \"\"\"Implements MoCo V2+ (https://arxiv.org/abs/2011.10566).\n",
    "\n",
    "        Args:\n",
    "            output_dim (int): number of dimensions of projected features.\n",
    "            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n",
    "            temperature (float): temperature for the softmax in the contrastive loss.\n",
    "            queue_size (int): number of samples to keep in the queue.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.queue_size = queue_size\n",
    "\n",
    "        # projector\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.features_dim, proj_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "        # momentum projector\n",
    "        self.momentum_projector = nn.Sequential(\n",
    "            nn.Linear(self.features_dim, proj_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_hidden_dim, output_dim),\n",
    "        )\n",
    "        initialize_momentum_params(self.projector, self.momentum_projector)\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(2, output_dim, queue_size))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=1)\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n",
    "        parent_parser = super(MoCoV2Plus, MoCoV2Plus).add_model_specific_args(parent_parser)\n",
    "        parser = parent_parser.add_argument_group(\"mocov2plus\")\n",
    "\n",
    "        # projector\n",
    "        parser.add_argument(\"--output_dim\", type=int, default=128)\n",
    "        parser.add_argument(\"--proj_hidden_dim\", type=int, default=2048)\n",
    "\n",
    "        # parameters\n",
    "        parser.add_argument(\"--temperature\", type=float, default=0.1)\n",
    "\n",
    "        # queue settings\n",
    "        parser.add_argument(\"--queue_size\", default=65536, type=int)\n",
    "\n",
    "        return parent_parser\n",
    "\n",
    "    @property\n",
    "    def learnable_params(self) -> List[dict]:\n",
    "        \"\"\"Adds projector parameters together with parent's learnable parameters.\n",
    "\n",
    "        Returns:\n",
    "            List[dict]: list of learnable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        extra_learnable_params = [{\"params\": self.projector.parameters()}]\n",
    "        return super().learnable_params + extra_learnable_params\n",
    "\n",
    "    @property\n",
    "    def momentum_pairs(self) -> List[Tuple[Any, Any]]:\n",
    "        \"\"\"Adds (projector, momentum_projector) to the parent's momentum pairs.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[Any, Any]]: list of momentum pairs.\n",
    "        \"\"\"\n",
    "\n",
    "        extra_momentum_pairs = [(self.projector, self.momentum_projector)]\n",
    "        return super().momentum_pairs + extra_momentum_pairs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys: torch.Tensor):\n",
    "        \"\"\"Adds new samples and removes old samples from the queue in a fifo manner.\n",
    "\n",
    "        Args:\n",
    "            keys (torch.Tensor): output features of the momentum encoder.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = keys.shape[1]\n",
    "        ptr = int(self.queue_ptr)  # type: ignore\n",
    "        assert self.queue_size % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        keys = keys.permute(0, 2, 1)\n",
    "        self.queue[:, :, ptr : ptr + batch_size] = keys\n",
    "        ptr = (ptr + batch_size) % self.queue_size  # move pointer\n",
    "        self.queue_ptr[0] = ptr  # type: ignore\n",
    "\n",
    "    def forward(self, X: torch.Tensor, *args, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Performs the forward pass of the online encoder and the online projection.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): a batch of images in the tensor format.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: a dict containing the outputs of the parent and the projected features.\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().forward(X, *args, **kwargs)\n",
    "        q = F.normalize(self.projector(out[\"feats\"]), dim=-1)\n",
    "        return {**out, \"q\": q}\n",
    "\n",
    "    def training_step(self, batch: Sequence[Any], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Training step for MoCo reusing BaseMomentumModel training step.\n",
    "\n",
    "        Args:\n",
    "            batch (Sequence[Any]): a batch of data in the\n",
    "                format of [img_indexes, [X], Y], where [X] is a list of size self.num_crops\n",
    "                containing batches of images.\n",
    "            batch_idx (int): index of the batch.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: total loss composed of MOCO loss and classification loss.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().training_step(batch, batch_idx)\n",
    "        class_loss = out[\"loss\"]\n",
    "        feats1, feats2 = out[\"feats\"]\n",
    "        momentum_feats1, momentum_feats2 = out[\"momentum_feats\"]\n",
    "\n",
    "        q1 = self.projector(feats1)\n",
    "        q2 = self.projector(feats2)\n",
    "        q1 = F.normalize(q1, dim=-1)\n",
    "        q2 = F.normalize(q2, dim=-1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            k1 = self.momentum_projector(momentum_feats1)\n",
    "            k2 = self.momentum_projector(momentum_feats2)\n",
    "            k1 = F.normalize(k1, dim=-1)\n",
    "            k2 = F.normalize(k2, dim=-1)\n",
    "\n",
    "        # ------- contrastive loss -------\n",
    "        # symmetric\n",
    "        queue = self.queue.clone().detach()\n",
    "        nce_loss = (\n",
    "            moco_loss_func(q1, k2, queue[1], self.temperature)\n",
    "            + moco_loss_func(q2, k1, queue[0], self.temperature)\n",
    "        ) / 2\n",
    "\n",
    "        # ------- update queue -------\n",
    "        keys = torch.stack((gather(k1), gather(k2)))\n",
    "        self._dequeue_and_enqueue(keys)\n",
    "\n",
    "        self.log(\"train_nce_loss\", nce_loss, on_epoch=True, sync_dist=True)\n",
    "\n",
    "        return nce_loss + class_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
