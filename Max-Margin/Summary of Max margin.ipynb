{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda509fc",
   "metadata": {},
   "source": [
    "Large-margin softmax: explicitly encourages intra-class compactness and inter-class separability between learned features.\n",
    "\n",
    "Using softmax loss, the label prediction rule is largely determined by the angular similarity to each class since softmax loss uses cosine distance as classification score.\n",
    "\n",
    "softmax loss:\n",
    "Suppose $x\\in$ class 1, then softmax is equivalent to $\\|W_1\\|\\|x\\| \\cos \\theta_1> \\|W_2\\|\\|x\\|\\cos\\theta_2$.\n",
    "Large margin softmax: increase the lower bound: $\\|W_1\\|\\|x\\| \\cos \\theta_1\\geq \\|W_1\\|\\|x\\| \\cos(m \\theta_1)>\\|W_2\\|\\|x\\|\\cos\\theta_2$,where $m$ determines the strength of getting closer to the ground truth class, producing an angular margin.\n",
    "\n",
    "It partially avoids overfitting by defining a more difficult learning target. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c9fd9",
   "metadata": {},
   "source": [
    "Personal comment: like a hinge loss in cosine similarity field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36448733",
   "metadata": {
    "code_folding": [
     27
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from scipy.special import binom\n",
    "\n",
    "\n",
    "class LSoftmaxLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, margin):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.margin = margin\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "\n",
    "        self.divisor = math.pi / self.margin\n",
    "        self.coeffs = binom(margin, range(0, margin + 1, 2))\n",
    "        self.cos_exps = range(self.margin, -1, -2)\n",
    "        self.sin_sq_exps = range(len(self.cos_exps))\n",
    "        self.signs = [1]\n",
    "        for i in range(1, len(self.sin_sq_exps)):\n",
    "            self.signs.append(self.signs[-1] * -1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_normal(self.weight.data.t())\n",
    "\n",
    "    def find_k(self, cos):\n",
    "        acos = cos.acos()\n",
    "        k = (acos / self.divisor).floor().detach()\n",
    "        return k\n",
    "\n",
    "    def forward(self, input, target=None):\n",
    "        if self.training:\n",
    "            assert target is not None\n",
    "            logit = input.matmul(self.weight)\n",
    "            batch_size = logit.size(0)\n",
    "            logit_target = logit[range(batch_size), target]\n",
    "            weight_target_norm = self.weight[:, target].norm(p=2, dim=0)\n",
    "            input_norm = input.norm(p=2, dim=1)\n",
    "            # norm_target_prod: (batch_size,)\n",
    "            norm_target_prod = weight_target_norm * input_norm\n",
    "            # cos_target: (batch_size,)\n",
    "            cos_target = logit_target / (norm_target_prod + 1e-10)\n",
    "            sin_sq_target = 1 - cos_target**2\n",
    "\n",
    "            num_ns = self.margin//2 + 1\n",
    "            # coeffs, cos_powers, sin_sq_powers, signs: (num_ns,)\n",
    "            coeffs = Variable(input.data.new(self.coeffs))\n",
    "            cos_exps = Variable(input.data.new(self.cos_exps))\n",
    "            sin_sq_exps = Variable(input.data.new(self.sin_sq_exps))\n",
    "            signs = Variable(input.data.new(self.signs))\n",
    "\n",
    "            cos_terms = cos_target.unsqueeze(1) ** cos_exps.unsqueeze(0)\n",
    "            sin_sq_terms = (sin_sq_target.unsqueeze(1)\n",
    "                            ** sin_sq_exps.unsqueeze(0))\n",
    "\n",
    "            cosm_terms = (signs.unsqueeze(0) * coeffs.unsqueeze(0)\n",
    "                          * cos_terms * sin_sq_terms)\n",
    "            cosm = cosm_terms.sum(1)\n",
    "            k = self.find_k(cos_target)\n",
    "\n",
    "            ls_target = norm_target_prod * (((-1)**k * cosm) - 2*k)\n",
    "            logit[range(batch_size), target] = ls_target\n",
    "            return logit\n",
    "        else:\n",
    "            assert target is None\n",
    "            return input.matmul(self.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
