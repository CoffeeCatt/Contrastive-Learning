{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image x--augment-->z_t, z_s\n",
    "\n",
    "$L(z_t,z_s)=l(z_t,q_s)+l(z_s,q_t).$\n",
    "\n",
    "$l(z_t,q_s)=-\\sum_{k}q_s^k \\log p_t^k$: assign a weighted prototype C, use this to predict q_s.\n",
    "\n",
    "Assignment: Sinkhorn Knopp.\n",
    "\n",
    "Online: queue.\n",
    "\n",
    "Multicrop: z_{t_v}, q_{t_i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     11
    ]
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def swav_loss_func(\n",
    "    preds: List[torch.Tensor], assignments: List[torch.Tensor], temperature: float = 0.1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Computes SwAV's loss given list of batch predictions from multiple views\n",
    "    and a list of cluster assignments from the same multiple views.\n",
    "    Args:\n",
    "        preds (torch.Tensor): list of NxC Tensors containing nearest neighbors' features from\n",
    "            view 1.\n",
    "        assignments (torch.Tensor): list of NxC Tensor containing predicted features from view 2.\n",
    "        temperature (torch.Tensor): softmax temperature for the loss. Defaults to 0.1.\n",
    "    Returns:\n",
    "        torch.Tensor: SwAV loss.\n",
    "    \"\"\"\n",
    "\n",
    "    losses = []\n",
    "    for v1 in range(len(preds)):\n",
    "        for v2 in np.delete(np.arange(len(preds)), v1):\n",
    "            a = assignments[v1]\n",
    "            p = preds[v2] / temperature\n",
    "            loss = -torch.mean(torch.sum(a * torch.log_softmax(p, dim=1), dim=1))\n",
    "            losses.append(loss)\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     24,
     49,
     81,
     93,
     110,
     146,
     148,
     152,
     172,
     181
    ]
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Any, Dict, List, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from solo.losses.swav import swav_loss_func\n",
    "from solo.methods.base import BaseModel\n",
    "from solo.utils.sinkhorn_knopp import SinkhornKnopp\n",
    "\n",
    "\n",
    "class SwAV(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim: int,\n",
    "        proj_hidden_dim: int,\n",
    "        num_prototypes: int,\n",
    "        sk_iters: int,\n",
    "        sk_epsilon: float,\n",
    "        temperature: float,\n",
    "        queue_size: int,\n",
    "        epoch_queue_starts: int,\n",
    "        freeze_prototypes_epochs: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Implements SwAV (https://arxiv.org/abs/2006.09882).\n",
    "        Args:\n",
    "            output_dim (int): number of dimensions of the projected features.\n",
    "            proj_hidden_dim (int): number of neurons in the hidden layers of the projector.\n",
    "            num_prototypes (int): number of prototypes.\n",
    "            sk_iters (int): number of iterations for the sinkhorn-knopp algorithm.\n",
    "            sk_epsilon (float): weight for the entropy regularization term.\n",
    "            temperature (float): temperature for the softmax normalization.\n",
    "            queue_size (int): number of samples to hold in the queue.\n",
    "            epoch_queue_starts (int): epochs the queue starts.\n",
    "            freeze_prototypes_epochs (int): number of epochs during which the prototypes are frozen.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.sk_iters = sk_iters\n",
    "        self.sk_epsilon = sk_epsilon\n",
    "        self.temperature = temperature\n",
    "        self.queue_size = queue_size\n",
    "        self.epoch_queue_starts = epoch_queue_starts\n",
    "        self.freeze_prototypes_epochs = freeze_prototypes_epochs\n",
    "\n",
    "        # projector\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.features_dim, proj_hidden_dim),\n",
    "            nn.BatchNorm1d(proj_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "        # prototypes\n",
    "        self.prototypes = nn.utils.weight_norm(nn.Linear(output_dim, num_prototypes, bias=False))\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n",
    "        parent_parser = super(SwAV, SwAV).add_model_specific_args(parent_parser)\n",
    "        parser = parent_parser.add_argument_group(\"swav\")\n",
    "\n",
    "        # projector\n",
    "        parser.add_argument(\"--output_dim\", type=int, default=128)\n",
    "        parser.add_argument(\"--proj_hidden_dim\", type=int, default=2048)\n",
    "\n",
    "        # queue settings\n",
    "        parser.add_argument(\"--queue_size\", default=3840, type=int)\n",
    "\n",
    "        # parameters\n",
    "        parser.add_argument(\"--temperature\", type=float, default=0.1)\n",
    "        parser.add_argument(\"--num_prototypes\", type=int, default=3000)\n",
    "        parser.add_argument(\"--sk_epsilon\", type=float, default=0.05)\n",
    "        parser.add_argument(\"--sk_iters\", type=int, default=3)\n",
    "        parser.add_argument(\"--freeze_prototypes_epochs\", type=int, default=1)\n",
    "        parser.add_argument(\"--epoch_queue_starts\", type=int, default=15)\n",
    "        return parent_parser\n",
    "\n",
    "    @property\n",
    "    def learnable_params(self) -> List[dict]:\n",
    "        \"\"\"Adds projector and prototypes parameters to the parent's learnable parameters.\n",
    "        Returns:\n",
    "            List[dict]: list of learnable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        extra_learnable_params = [\n",
    "            {\"params\": self.projector.parameters()},\n",
    "            {\"params\": self.prototypes.parameters()},\n",
    "        ]\n",
    "        return super().learnable_params + extra_learnable_params\n",
    "\n",
    "    def on_train_start(self):\n",
    "        \"\"\"Gets the world size and sets it in the sinkhorn and the queue.\"\"\"\n",
    "        # sinkhorn-knopp needs the world size\n",
    "        world_size = self.trainer.world_size if self.trainer else 1\n",
    "        self.sk = SinkhornKnopp(self.sk_iters, self.sk_epsilon, world_size)\n",
    "        # queue also needs the world size\n",
    "        if self.queue_size > 0:\n",
    "            self.register_buffer(\n",
    "                \"queue\",\n",
    "                torch.zeros(\n",
    "                    2,\n",
    "                    self.queue_size // world_size,\n",
    "                    self.output_dim,\n",
    "                    device=self.device,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def forward(self, X: torch.Tensor, *args, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Performs the forward pass of the encoder, the projector and the prototypes.\n",
    "        Args:\n",
    "            X (torch.Tensor): a batch of images in the tensor format.\n",
    "        Returns:\n",
    "            Dict[str, Any]:\n",
    "                a dict containing the outputs of the parent,\n",
    "                the projected features and the logits.\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().forward(X, *args, **kwargs)\n",
    "        z = self.projector(out[\"feats\"])\n",
    "        z = F.normalize(z)\n",
    "        p = self.prototypes(z)\n",
    "        return {**out, \"z\": z, \"p\": p}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_assignments(self, preds: List[torch.Tensor]) -> List[torch.Tensor]:\n",
    "        \"\"\"Computes cluster assignments from logits, optionally using a queue.\n",
    "        Args:\n",
    "            preds (List[torch.Tensor]): a batch of logits.\n",
    "        Returns:\n",
    "            List[torch.Tensor]: assignments for each sample in the batch.\n",
    "        \"\"\"\n",
    "\n",
    "        bs = preds[0].size(0)\n",
    "        assignments = []\n",
    "        for i, p in enumerate(preds):\n",
    "            # optionally use the queue\n",
    "            if self.queue_size > 0 and self.current_epoch >= self.epoch_queue_starts:\n",
    "                p_queue = self.prototypes(self.queue[i])  # type: ignore\n",
    "                p = torch.cat((p, p_queue))\n",
    "            # compute assignments with sinkhorn-knopp\n",
    "            assignments.append(self.sk(p)[:bs])\n",
    "        return assignments\n",
    "\n",
    "    def training_step(self, batch: Sequence[Any], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step for SwAV reusing BaseModel training step.\n",
    "        Args:\n",
    "            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n",
    "                [X] is a list of size self.num_crops containing batches of images.\n",
    "            batch_idx (int): index of the batch.\n",
    "        Returns:\n",
    "            torch.Tensor: total loss composed of SwAV loss and classification loss.\n",
    "        \"\"\"\n",
    "\n",
    "        out = super().training_step(batch, batch_idx)\n",
    "        class_loss = out[\"loss\"]\n",
    "        feats1, feats2 = out[\"feats\"]\n",
    "\n",
    "        z1 = F.normalize(self.projector(feats1))\n",
    "        z2 = F.normalize(self.projector(feats2))\n",
    "\n",
    "        p1 = self.prototypes(z1)\n",
    "        p2 = self.prototypes(z2)\n",
    "\n",
    "        # ------- swav loss -------\n",
    "        preds = [p1, p2]\n",
    "        assignments = self.get_assignments(preds)\n",
    "        swav_loss = swav_loss_func(preds, assignments, self.temperature)\n",
    "\n",
    "        # ------- update queue -------\n",
    "        if self.queue_size > 0:\n",
    "            z = torch.stack((z1, z2))\n",
    "            self.queue[:, z.size(1) :] = self.queue[:, : -z.size(1)].clone()\n",
    "            self.queue[:, : z.size(1)] = z.detach()\n",
    "\n",
    "        self.log(\"train_swav_loss\", swav_loss, on_epoch=True, sync_dist=True)\n",
    "\n",
    "        return swav_loss + class_loss\n",
    "\n",
    "    def on_after_backward(self):\n",
    "        \"\"\"Zeroes the gradients of the prototypes.\"\"\"\n",
    "        if self.current_epoch < self.freeze_prototypes_epochs:\n",
    "            for p in self.prototypes.parameters():\n",
    "                p.grad = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
